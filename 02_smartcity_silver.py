# Databricks notebook source
# MAGIC %md
# MAGIC ### Cleaning Data - Silver Layer

# COMMAND ----------

# MAGIC %run "./00_smartcity_configs"

# COMMAND ----------

from pyspark.sql.functions import col, to_timestamp, current_timestamp, trim, to_date, lit, when
from functools import reduce

# COMMAND ----------

airquality_bronze = spark.read.format("delta").load(f"{bronze_path}air_quality_raw_delta/")
buildingpermits_bronze = spark.read.format("delta").load(f"{bronze_path}building_permits_raw_delta/")
energy_bronze = spark.read.format("delta").load(f"{bronze_path}energy_raw_delta/")
traffic_bronze = spark.read.format("delta").load(f"{bronze_path}traffic_raw_delta/")
transport_bronze = spark.read.format("delta").load(f"{bronze_path}transport_raw_delta/")
waste_bronze = spark.read.format("delta").load(f"{bronze_path}waste_raw_delta/")
cityzones_bronze = spark.read.format("delta").load(f"{bronze_path}city_zones_raw_delta/")
sensormetadata_bronze = spark.read.format("delta").load(f"{bronze_path}sensor_metadata_raw_delta/")
truckfleet_bronze = spark.read.format("delta").load(f"{bronze_path}truck_fleet_raw_delta/")


# COMMAND ----------

numcols = ["pm2_5","pm10","co_level", "so2_level", "humidity"]

airquality_silver = airquality_bronze \
.withColumn("reading_time", to_timestamp("reading_time", "yyyy-MM-dd'T'HH:mm:ss")) \
.dropna(subset=["station_id", "reading_time"]) \
.dropDuplicates(["station_id", "reading_time"]) \
.filter(reduce(lambda a, b: a & b, [col(numcol) >= 0.0 for numcol in numcols])) \
.withColumn("ingestion_time", current_timestamp())


# COMMAND ----------

building_permits_silver = buildingpermits_bronze \
.dropDuplicates(["permit_id"]) \
.withColumn("issue_date", to_date("issue_date", "yyyy-MM-dd")) \
.withColumn("estimated_cost", col("estimated_cost").cast("double")) \
.withColumn("address", trim(col("address"))) \
.dropna(subset=["permit_id", "issue_date", "address", "contractor"]) \
.filter(col("estimated_cost") > 0) \
.withColumn("ingestion_time", current_timestamp())

# COMMAND ----------

energy_silver = energy_bronze \
.dropDuplicates(["reading_date", "sector_id", "meter_id"]) \
.withColumn("reading_date", to_date("reading_date", "yyyy-MM-dd")) \
.withColumn("energy_kwh", col("energy_kwh").cast("double")) \
.withColumn("supply_area", trim(col("supply_area"))) \
.dropna(subset=["reading_date", "sector_id", "meter_id"]) \
.filter(col("energy_kwh") > 0) \
.filter(col("peak_load_time_hour").between("0", "23") ) \
.withColumn("ingestion_time", current_timestamp())

# COMMAND ----------

traffic_silver  = traffic_bronze \
.withColumn("timestamp", to_timestamp("timestamp", "yyyy-MM-dd HH:mm:ss")) \
.withColumn("road_name", trim(col("road_name"))) \
.dropna(subset=["vehicle_count", "timestamp", "sensor_id"]) \
.filter((col("vehicle_count") > 0) & (col("average_speed_kmph").between("0","200"))) \
.withColumn("traffic_jam_indicator", when(col("traffic_jam_indicator").isin(["low","medium","high"]), \
                                          col("traffic_jam_indicator")).otherwise(lit("unknown"))) \
.withColumn("ingestion_time", current_timestamp())

# COMMAND ----------

transport_silver = transport_bronze \
    .withColumn("timestamp", to_timestamp(col("timestamp"), "yyyy-MM-dd HH:mm:ss")) \
    .dropna(subset=["trip_id", "timestamp", "bus_id", "route_number"]) \
    .dropDuplicates(["trip_id", "timestamp", "bus_id"]) \
    .filter((col("passenger_count")>0) & (col("average_wait_time") > 0)) \
    .withColumn("ingestion_time", current_timestamp())

# COMMAND ----------

waste_silver = waste_bronze \
    .withColumn("weight_kg", col("weight_kg").cast("double")) \
    .filter(col("weight_kg") > 0) \
    .dropna(subset=["collection_date", "zone_id", "waste_type"]) \
    .dropDuplicates(["collection_date", "zone_id", "waste_type", "truck_id"]) \
    .withColumn("collection_status", when(col("collection_status").isin(["missed", "partial", "completed"]), 
                                          col("collection_status")).otherwise(lit("unknown"))) \
    .withColumn("route_id", trim(col("route_id"))) \
    .withColumn("ingestion_time", current_timestamp())

# COMMAND ----------

cityzones_silver = cityzones_bronze \
.dropna(subset=["zone_id", "zone_name"]) \
.dropDuplicates(["zone_id", "zone_name"]) \
.filter((col("population_density")> 0) & (col("area_sq_km")> 0)) \
.withColumn("ingestion_time", current_timestamp())

# COMMAND ----------

sensormetadata_silver = sensormetadata_bronze \
.dropna(subset=["sensor_id","installation_date", "sensor_type"]) \
.filter((col("location_lat").between("-90","90")) & (col("location_long").between("-180","180"))) \
.withColumn("ingestion_time", current_timestamp())

# COMMAND ----------

truckfleet_silver = truckfleet_bronze \
.dropna(subset=["truck_id", "capacity_kg"]) \
.filter(col("capacity_kg") > 0) \
.withColumn("ingestion_time", current_timestamp())

# COMMAND ----------

airquality_silver.write.format("delta").mode("overwrite").save(f"{silver_path}air_quality_cleaned_delta/")
building_permits_silver.write.format("delta").mode("overwrite").save(f"{silver_path}building_permits_cleaned_delta/")
energy_silver.write.format("delta").mode("overwrite").save(f"{silver_path}energy_cleaned_delta/")
traffic_silver.write.format("delta").mode("overwrite").save(f"{silver_path}traffic_cleaned_delta/")
transport_silver.write.format("delta").mode("overwrite").save(f"{silver_path}transport_cleaned_delta/")
waste_silver.write.format("delta").mode("overwrite").save(f"{silver_path}waste_cleaned_delta/")
cityzones_silver.write.format("delta").mode("overwrite").save(f"{silver_path}cityzones_cleaned_delta/")
sensormetadata_silver.write.format("delta").mode("overwrite").save(f"{silver_path}sensormetadata_cleaned_delta/")
truckfleet_silver.write.format("delta").mode("overwrite").save(f"{silver_path}truckfleet_cleaned_delta/")

# COMMAND ----------

